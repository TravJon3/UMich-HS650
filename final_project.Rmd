---
title: "Final Project"
subtitle: "Summary, Evaluation, and Conclusions"
author: "Kevin Wu"
date: "`r format(Sys.time(), '%B %Y')`"
tags: [DSPA, SOCR, MIDAS, Big Data, Predictive Analytics] 
output:
  html_document:
    theme: spacelab
    highlight: tango
    toc: true
    number_sections: true
    toc_depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: true
    code_folding: show
    self_contained: yes
---
**final_project.Rmd**.

 * Final Project
 * Fall 2021, DSPA (HS650)
 * Name: Kevin Wu
 * SID: ####0012 (last 4 digits only)
 * UMich E-mail: kevinkwu@umich.edu
 * I certify that the following paper represents my own independent work and conforms with the guidelines of academic honesty described in the UMich student handbook.
 * Remember that students are allowed and encouraged to discuss, on a conceptual level, the problems with your class mates, however, this can not involve the exchange of actual code, printouts, solutions, e-mails or other explicit electronic or paper handouts.


# Final Project Introduction
<p>The PSID (Panel Study of Income Dynamics) began in 1968, studying over 18,000 individuals living in 5,000 families.  In 1997, the PSID launched the CDS (Child Development Supplement) I-III studying the children of these families.  The TAS (Transition into Adulthood Supplement) began in 2005 which collected data from these very children transitioning into young adults.  The following data is a custom dataset composed of the CDSII (children interviewed in 2001) and follows these children in the TAS 2011.</p>

<p>Want to know (i.e. dependent variable) "change" = 2 (desirable move/state) vs 0 (steady but not ideal move/state) & 1 (undesirable move/state)</p>
<p>The questions I'm looking to answer are</p>
* <b>What model makes the best prediction for teens that flourish?</b>
* <b>What are the best predictors?</b>

<p>These are the methods of approaches I will take to analyze the data</p>
1. Use feature selection models (OLS, rfe, Boruta) and confirm them with PCA.
2. Use clustering nearest neighbors (k-Means, kNN) and check with SVM.
3. Use classification trees (neuralnet, randomForest) and check with rpart.
4. Start with lm multiple regression, and then use cv.glmnet and BART to confirm.
5. Compare with apriori techniques.

```{r Introduction, warning=F, message=F, include=F, child='final_project_common.Rmd'}
```

# Dataset Details
<p>The following dataset I am analyzing is a filtered version of a <a href="https://www.openicpsr.org/openicpsr/project/143381/version/V1/view">custom dataset</a> Dr. Ashley Palmer compiled from a <a href="https://psycnet.apa.org/record/2006-11985-014">study done by Dr. Corey Keyes in 2006</a> using the CDSII data.</p>
<p>The following features were removed from Dr. Palmer's custom dataset because they were derived from the original CDSII and TAS2011 questions that are used to create the "change" features - the features that I am studying.</p>
<p>In the effort to factorialize "mhstatus" and "change" I had to either remove the missing values, or account for them.  Since there is no way to determine whether a missing value indicates a languishing status (perhaps due to the incomplete nature of the survey) or an incomplete status, I chose to remove them as my main focus is what features aid in positive changes.  As such, by removing 30% or 835 participant surveys, the data is heavily skewed toward those experiencing positive changes.</p>
<p>I also created a separate dataset containing only objective data, as through my modeling, I noticed a lot of the subjective indicators were strongly influencing the outcomes.  I wanted to see what was contributing to these subjective indicators, so I created a dataset of only "objective" features.</p>
<p>Many features are nominal, making it inappropriate to scale the features.  FIX THIS........With roughly 300 features that are similar in nature.......FIX THIS</p>
[Header File: Defining Datasets](final_project_common.html)
```{r Dataset Details, warning=F, message=F}
#load and convert Stata data into R dataframe frames into environment

ncol(df_filtered)
nrow(df_filtered)
ncol(df_filtered_objective)
nrow(df_filtered_objective)

convertStatDataType <- function(strType) {
  mapping <- c("%8.0g"="byte", "%8.0g"="int", "%12.0g"="long", "%9.0g"="float", "%10.0g"="double", "%#s"="str#", "%9s"="strL")
  mapping[strType]
}

convertDataframeDisplay <- function(df_convert) {
  dfDisplay <- data.frame(matrix(ncol = 0, nrow = ncol(df_convert)))
  vectName <- vector(length = ncol(df_convert))
  vectLabel <- vector(length = ncol(df_convert))
  vectFormat <- vector(length = ncol(df_convert))
  vectDescriptions <- vector(length = ncol(df_convert))
  
  for(i in 1:ncol(df_convert)) {
    vectName[i] <- names(df_convert[, i])
    if(is.null(attributes(df_convert[[i]])$label) == F)
      vectLabel[i] <- attributes(df_convert[[i]])$label
    if(is.null(attributes(df_convert[[i]])$format.stata) == F)
      vectFormat[i] <- lapply(attributes(df_convert[[i]])$format.stata, convertStatDataType)
    if(is.null(attributes(df_convert[[i]])$class) == F && attributes(df_convert[[i]])$class == "factor") {
      vectFormat[i] <- "factor"
      vectDescriptions[i] <- str_flatten(attributes(df_convert[[i]])$levels, "<br />")
    }
    if(is.null(attributes(df_convert[[i]])$class) == F && attributes(df_convert[[i]])$class != "factor" && attributes(df_convert[[i]])$class[3] == "double")
      vectFormat[i] <- "double"
    if(is.null(attributes(df_convert[[i]])$labels) == F && length(attributes(df_convert[[i]])$labels) > 0) {
      vectLabels <- list(length(attributes(df_convert[[i]])$labels))
      for(j in 1:length(attributes(df_convert[[i]])$labels)) {
        vectLabels[j] <- as.character(attributes(df_convert[[i]])$labels[j])
        if(is.null(names(attributes(df_convert[[i]])$labels[j])) == F && as.character(names(attributes(df_convert[[i]])$labels[j])) != "Actual number")
          vectLabels[j] <- paste(c(vectLabels[j], ":", as.character(names(attributes(df_convert[[i]])$labels[j]))), collapse = " ")
        else if(as.character(names(attributes(df_convert[[i]])$labels[j])) == "Actual number")
          vectLabels[j] <- paste0(vectLabels[j], ":::")
      }
      vectDescriptions[i] <- str_flatten(vectLabels, "<br />")
      vectDescriptions[i] <- str_replace_all(vectDescriptions[i], ":::<br />", ", ")
    }
  }
  dfDisplay$ColumnName <- vectName
  dfDisplay$Label <- vectLabel
  dfDisplay$Format<- vectFormat
  dfDisplay$Labels <- vectDescriptions
  return(dfDisplay)
}
```
## Filtered Dataframe aka Full Dataset
```{r Dataset Details All, warning=F, message=F}
df_display <- convertDataframeDisplay(df_filtered_non_int)
datatable(df_display, options = list(
  pageLength=10,
  lengthMenu=c(10,50,100,150,250,300)
  ),
  escape=F
)
```

## Filtered Dataframe with Only Objective Data aka Objective Dataset
```{r Dataset Details Objective, warning=F, message=F}
df_objective_display <- convertDataframeDisplay(df_filtered_objective_non_int)
datatable(df_objective_display, options = list(
  pageLength=10,
  lengthMenu=c(10,50,100,150,250,300)
  ),
  escape=F
)
```

# Data Distribution
```{r Data Distribution, warning=F, message=F}
plot_ly(x = ~mhstatus, type="histogram") %>%
  layout(title = "Distribution of Mental Health Status", xaxis = list(title = "Mental Health Status"), bargap=0.1,
         legend = list(orientation = 'h', title = list(text = "<b>Mental Health</b>")))
```
## Comparison Between Training and Testing Data
```{r DDTrainingTest, warning=F, message=F}

prop.table(table(mhstatus_train))
prop.table(table(mhstatus_test))
prop.table(table(df_train$PositiveChange))
prop.table(table(df_test$PositiveChange))
```